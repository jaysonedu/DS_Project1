{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9761caa0-f0dc-4aac-bb20-33d5402d5ea0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nStep1:\\n1.Read the Zillow ZHVI CSV.\\n2.Detect all monthly date columns (YYYY-MM-DD).\\n3.Convert the wide table into a long table (zip, month, zhvi).\\n4.Filter to keep only records from January 2023 and later.\\n5.Convert the month column from full date (e.g., 2023-01-31) to year-month format (e.g., 2023-01).\\n'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Step1:\n",
        "1.Read the Zillow ZHVI CSV.\n",
        "2.Detect all monthly date columns (YYYY-MM-DD).\n",
        "3.Convert the wide table into a long table (zip, month, zhvi).\n",
        "4.Filter to keep only records from January 2023 and later.\n",
        "5.Convert the month column from full date (e.g., 2023-01-31) to year-month format (e.g., 2023-01).\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b635965e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Project root so \"from src.acquire\" and data paths work from any cwd\n",
        "ROOT = Path.cwd()\n",
        "while ROOT != ROOT.parent and not (ROOT / \"pyproject.toml\").exists():\n",
        "    ROOT = ROOT.parent\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "from src.acquire._loaders import load_all_newest\n",
        "results = load_all_newest()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "11c814ca-eab8-4dd7-9433-711d34322fbb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Zillow file: zillow_zhvi_20260212_165121.csv -> shape (26307, 321)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jason\\AppData\\Local\\Temp\\ipykernel_8248\\4293575548.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  zillow[\"zip\"] = zillow[\"RegionName\"].astype(str).str.zfill(5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     zip    month           zhvi\n",
            "0  01001  2023-01  284265.293218\n",
            "1  01001  2023-02  285125.304634\n",
            "2  01001  2023-03  286436.003321\n",
            "3  01001  2023-04  288442.991612\n",
            "4  01001  2023-05  290659.546155\n",
            "5  01001  2023-06  292723.607850\n",
            "6  01001  2023-07  294840.366054\n",
            "7  01001  2023-08  297214.654496\n",
            "8  01001  2023-09  299622.269960\n",
            "9  01001  2023-10  301303.118047\n",
            "Shape: (947052, 3)\n"
          ]
        }
      ],
      "source": [
        "# Use newest raw files from load_all_newest() (run cell above first)\n",
        "if \"zillow\" not in results or results[\"zillow\"][1] is None:\n",
        "    raise FileNotFoundError(\"No Zillow ZHVI CSV file found in 'data/raw/zillow/'. Please download or generate data.\")\n",
        "latest_zillow_path, zillow = results[\"zillow\"]\n",
        "print(f\"Loading Zillow file: {latest_zillow_path.name} -> shape {zillow.shape}\")\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Identify columns in YYYY-MM-DD format\n",
        "date_pattern = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}$\")\n",
        "date_cols = [col for col in zillow.columns if date_pattern.match(str(col))]\n",
        "\n",
        "if len(date_cols) == 0:\n",
        "    raise ValueError(\"No monthly date columns found. Please check your Zillow column names.\")\n",
        "\n",
        "date_cols = sorted(date_cols)\n",
        "\n",
        "# Build (zip, month, zhvi) long table\n",
        "zillow[\"zip\"] = zillow[\"RegionName\"].astype(str).str.zfill(5)\n",
        "zillow_small = zillow[[\"zip\"] + date_cols].copy()\n",
        "\n",
        "zillow_long = pd.melt(\n",
        "    zillow_small,\n",
        "    id_vars=[\"zip\"],\n",
        "    value_vars=date_cols,\n",
        "    var_name=\"month\",\n",
        "    value_name=\"zhvi\"\n",
        ")\n",
        "zillow_long[\"month\"] = pd.to_datetime(zillow_long[\"month\"], errors=\"coerce\")\n",
        "\n",
        "# Filter to keep >= 2023-01-01\n",
        "zillow_long = zillow_long[zillow_long[\"month\"] >= pd.Timestamp(\"2023-01-01\")].copy()\n",
        "\n",
        "# Convert month to Year-Month format (YYYY-MM)\n",
        "zillow_long[\"month\"] = zillow_long[\"month\"].dt.to_period(\"M\").astype(str)\n",
        "zillow_long = zillow_long.sort_values([\"zip\", \"month\"]).reset_index(drop=True)\n",
        "\n",
        "print(zillow_long.head(10))\n",
        "print(\"Shape:\", zillow_long.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c3c80456-3ee7-4336-a73b-baf889fca13e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nStep2:\\n1.Read the ACS CSV.\\n2.Keep the key socioeconomic columns, rename them to readable feature names, and create a few basic derived features (rates).\\n3.Standardize the ZIP key to a 5-digit string.\\n4.Merge ACS features into the Zillow long table on zip, and save the merged dataset for the next steps.\\n'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Step2:\n",
        "1.Read the ACS CSV.\n",
        "2.Keep the key socioeconomic columns, rename them to readable feature names, and create a few basic derived features (rates).\n",
        "3.Standardize the ZIP key to a 5-digit string.\n",
        "4.Merge ACS features into the Zillow long table on zip, and save the merged dataset for the next steps.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "18b4e315-f8c2-4d94-826a-2b15c5127c82",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     zip    month           zhvi  population  median_income  poverty_base  \\\n",
            "0  01001  2023-01  284265.293218     16136.0        71924.0       15624.0   \n",
            "1  01001  2023-02  285125.304634     16136.0        71924.0       15624.0   \n",
            "2  01001  2023-03  286436.003321     16136.0        71924.0       15624.0   \n",
            "3  01001  2023-04  288442.991612     16136.0        71924.0       15624.0   \n",
            "4  01001  2023-05  290659.546155     16136.0        71924.0       15624.0   \n",
            "\n",
            "   poverty_count  labor_force  unemployed  edu_bachelors  edu_masters  \\\n",
            "0         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "1         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "2         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "3         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "4         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "\n",
            "   edu_professional  edu_doctorate  poverty_rate  unemployment_rate  \\\n",
            "0             223.0          226.0      0.072325           0.051815   \n",
            "1             223.0          226.0      0.072325           0.051815   \n",
            "2             223.0          226.0      0.072325           0.051815   \n",
            "3             223.0          226.0      0.072325           0.051815   \n",
            "4             223.0          226.0      0.072325           0.051815   \n",
            "\n",
            "   higher_ed_count  \n",
            "0           4365.0  \n",
            "1           4365.0  \n",
            "2           4365.0  \n",
            "3           4365.0  \n",
            "4           4365.0  \n",
            "Shape: (947052, 16)\n"
          ]
        }
      ],
      "source": [
        "# Standardize ZIP\n",
        "zillow_long[\"zip\"] = zillow_long[\"zip\"].astype(str).str.zfill(5)\n",
        "\n",
        "# Convert to datetime first\n",
        "zillow_long[\"month\"] = pd.to_datetime(zillow_long[\"month\"], errors=\"coerce\")\n",
        "\n",
        "# ====== CHANGE HERE ======\n",
        "# Convert from full date (e.g., 2023-01-31) to Year-Month format (e.g., 2023-01)\n",
        "zillow_long[\"month\"] = zillow_long[\"month\"].dt.to_period(\"M\").astype(str)\n",
        "# =========================\n",
        "\n",
        "# ====== 1) Read ACS raw data (newest from data/raw/acs/) ======\n",
        "if \"acs\" not in results or results[\"acs\"][1] is None:\n",
        "    raise FileNotFoundError(\"No ACS file found in data/raw/acs/. Run the ACS acquirer first.\")\n",
        "_, acs = results[\"acs\"]\n",
        "acs = acs.copy()\n",
        "\n",
        "# ====== 2) Select key ACS columns ======\n",
        "keep_cols = [\n",
        "    \"zip code tabulation area\",\n",
        "    \"B01003_001E\",\n",
        "    \"B19013_001E\",\n",
        "    \"B17001_001E\",\n",
        "    \"B17001_002E\",\n",
        "    \"B23025_003E\",\n",
        "    \"B23025_005E\",\n",
        "    \"B15003_022E\",\n",
        "    \"B15003_023E\",\n",
        "    \"B15003_024E\",\n",
        "    \"B15003_025E\",\n",
        "]\n",
        "\n",
        "acs_small = acs[keep_cols].copy()\n",
        "\n",
        "# Rename columns\n",
        "acs_small = acs_small.rename(columns={\n",
        "    \"zip code tabulation area\": \"zip\",\n",
        "    \"B01003_001E\": \"population\",\n",
        "    \"B19013_001E\": \"median_income\",\n",
        "    \"B17001_001E\": \"poverty_base\",\n",
        "    \"B17001_002E\": \"poverty_count\",\n",
        "    \"B23025_003E\": \"labor_force\",\n",
        "    \"B23025_005E\": \"unemployed\",\n",
        "    \"B15003_022E\": \"edu_bachelors\",\n",
        "    \"B15003_023E\": \"edu_masters\",\n",
        "    \"B15003_024E\": \"edu_professional\",\n",
        "    \"B15003_025E\": \"edu_doctorate\",\n",
        "})\n",
        "\n",
        "# Standardize ZIP\n",
        "acs_small[\"zip\"] = acs_small[\"zip\"].astype(str).str.zfill(5)\n",
        "\n",
        "# Derived features\n",
        "acs_small[\"poverty_rate\"] = acs_small[\"poverty_count\"] / acs_small[\"poverty_base\"]\n",
        "acs_small[\"unemployment_rate\"] = acs_small[\"unemployed\"] / acs_small[\"labor_force\"]\n",
        "acs_small[\"higher_ed_count\"] = (\n",
        "    acs_small[\"edu_bachelors\"]\n",
        "    + acs_small[\"edu_masters\"]\n",
        "    + acs_small[\"edu_professional\"]\n",
        "    + acs_small[\"edu_doctorate\"]\n",
        ")\n",
        "\n",
        "# Merge\n",
        "zillow_acs = zillow_long.merge(acs_small, on=\"zip\", how=\"left\")\n",
        "\n",
        "print(zillow_acs.head())\n",
        "print(\"Shape:\", zillow_acs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b269933a-0a98-42ab-93d1-c41213be4988",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nStep3:\\n1.Spatial Assignment of ZIP Codes:\\nThe crime dataset contains incident-level records with latitude and longitude but no ZIP code. The MODZCTA dataset provides polygon boundaries for ZIP areas. We converted the the_geom field into polygon geometries and transformed each crime record into a geographic point. A point-in-polygon spatial join was performed to assign a ZIP code to each crime event.\\n2. Temporal Standardization:\\nThe cmplnt_fr_dt field was converted to datetime format. Dates were transformed into a Year-Month format (YYYY-MM) to match the monthly structure of the housing dataset.\\n3. Monthly ZIP-Level Aggregation:\\nCrime records were grouped by (zip, month). The total number of incidents per ZIP per month was computed as crime_count.\\n4. Integration with Main Dataset:\\nThe ZIP-month crime counts were merged into zillow_acs using a left join on (zip, month). Missing values were replaced with 0 to indicate no recorded crime for that ZIP-month.\\n'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Step3:\n",
        "1.Spatial Assignment of ZIP Codes:\n",
        "The crime dataset contains incident-level records with latitude and longitude but no ZIP code. The MODZCTA dataset provides polygon boundaries for ZIP areas. We converted the the_geom field into polygon geometries and transformed each crime record into a geographic point. A point-in-polygon spatial join was performed to assign a ZIP code to each crime event.\n",
        "2. Temporal Standardization:\n",
        "The cmplnt_fr_dt field was converted to datetime format. Dates were transformed into a Year-Month format (YYYY-MM) to match the monthly structure of the housing dataset.\n",
        "3. Monthly ZIP-Level Aggregation:\n",
        "Crime records were grouped by (zip, month). The total number of incidents per ZIP per month was computed as crime_count.\n",
        "4. Integration with Main Dataset:\n",
        "The ZIP-month crime counts were merged into zillow_acs using a left join on (zip, month). Missing values were replaced with 0 to indicate no recorded crime for that ZIP-month.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0074bb58-f818-46dd-a03c-55375806b2a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Crime points after cleaning: 577674\n",
            "ZCTA polygons: 178\n",
            "Matched crimes (joined): 577639\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely import wkt\n",
        "\n",
        "# Inputs: newest crime from data/raw/nyc_crime/, MODZCTA from data/raw/geo/\n",
        "if \"nyc_crime\" not in results or results[\"nyc_crime\"][1] is None:\n",
        "    raise FileNotFoundError(\"No NYC crime file found in data/raw/nyc_crime/. Run the nyc_crime acquirer first.\")\n",
        "_, crime = results[\"nyc_crime\"]\n",
        "crime = crime.copy()\n",
        "\n",
        "geo_dir = ROOT / \"data\" / \"raw\" / \"geo\"\n",
        "modzcta_files = list(geo_dir.glob(\"*MODZCTA*.csv\")) if geo_dir.exists() else []\n",
        "if not modzcta_files:\n",
        "    modzcta_files = list(geo_dir.glob(\"*.csv\")) if geo_dir.exists() else []\n",
        "modzcta_path = max(modzcta_files, key=lambda p: p.stat().st_mtime) if modzcta_files else None\n",
        "if modzcta_path is None:\n",
        "    raise FileNotFoundError(\"No MODZCTA CSV found in data/raw/geo/. Place Modified_Zip_Code_Tabulation_Areas__MODZCTA_.csv there.\")\n",
        "\n",
        "# df is already in memory\n",
        "df = zillow_acs.copy()\n",
        "\n",
        "# Make sure keys are standardized\n",
        "df[\"zip\"] = df[\"zip\"].astype(str).str.zfill(5)\n",
        "df[\"month\"] = df[\"month\"].astype(str)  # should already be 'YYYY-MM'\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# STEP 1) Assign ZIP (MODZCTA) to each crime using lat/lon + polygons\n",
        "# =========================================================\n",
        "\n",
        "# 1.1 Read MODZCTA polygons\n",
        "zcta = pd.read_csv(modzcta_path)\n",
        "\n",
        "zcta_small = zcta[[\"MODZCTA\", \"the_geom\"]].copy()\n",
        "zcta_small[\"zip\"] = zcta_small[\"MODZCTA\"].astype(str).str.zfill(5)\n",
        "\n",
        "# Parse WKT -> geometry\n",
        "zcta_small = zcta_small.dropna(subset=[\"the_geom\"])\n",
        "zcta_small[\"geometry\"] = zcta_small[\"the_geom\"].apply(wkt.loads)\n",
        "\n",
        "zcta_gdf = gpd.GeoDataFrame(\n",
        "    zcta_small[[\"zip\", \"geometry\"]],\n",
        "    geometry=\"geometry\",\n",
        "    crs=\"EPSG:4326\"  # lon/lat\n",
        ")\n",
        "\n",
        "# 1.2 Crime points (already loaded from results; only need lat/lon + date)\n",
        "needed_cols = [\"cmplnt_fr_dt\", \"latitude\", \"longitude\"]\n",
        "crime_small = crime[needed_cols].copy()\n",
        "\n",
        "# Convert lat/lon to numeric\n",
        "crime_small[\"latitude\"] = pd.to_numeric(crime_small[\"latitude\"], errors=\"coerce\")\n",
        "crime_small[\"longitude\"] = pd.to_numeric(crime_small[\"longitude\"], errors=\"coerce\")\n",
        "crime_small = crime_small.dropna(subset=[\"latitude\", \"longitude\"])\n",
        "\n",
        "# ---- Auto-fix possible swapped lat/lon ----\n",
        "# If many \"latitude\" values look like -73 (should be lon), swap them.\n",
        "lat_looks_like_lon = (crime_small[\"latitude\"].between(-75, -72)).mean()\n",
        "lon_looks_like_lat = (crime_small[\"longitude\"].between(40, 41.5)).mean()\n",
        "\n",
        "if lat_looks_like_lon > 0.5 and lon_looks_like_lat > 0.5:\n",
        "    # swap columns\n",
        "    tmp = crime_small[\"latitude\"].copy()\n",
        "    crime_small[\"latitude\"] = crime_small[\"longitude\"]\n",
        "    crime_small[\"longitude\"] = tmp\n",
        "    print(\"Detected swapped lat/lon -> swapped back.\")\n",
        "\n",
        "# ---- Keep only points in NYC-ish bounding box (helps avoid bad coords) ----\n",
        "crime_small = crime_small[\n",
        "    crime_small[\"longitude\"].between(-75, -72) &\n",
        "    crime_small[\"latitude\"].between(40.0, 41.2)\n",
        "].copy()\n",
        "\n",
        "# Convert date -> datetime (we will need it later)\n",
        "crime_small[\"cmplnt_fr_dt\"] = pd.to_datetime(crime_small[\"cmplnt_fr_dt\"], errors=\"coerce\")\n",
        "crime_small = crime_small.dropna(subset=[\"cmplnt_fr_dt\"])\n",
        "\n",
        "# Build GeoDataFrame for points\n",
        "crime_gdf = gpd.GeoDataFrame(\n",
        "    crime_small,\n",
        "    geometry=gpd.points_from_xy(crime_small[\"longitude\"], crime_small[\"latitude\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "# 1.3 Spatial join: point-in-polygon\n",
        "crime_joined = gpd.sjoin(crime_gdf, zcta_gdf, how=\"inner\", predicate=\"intersects\")\n",
        "\n",
        "print(\"Crime points after cleaning:\", len(crime_gdf))\n",
        "print(\"ZCTA polygons:\", len(zcta_gdf))\n",
        "print(\"Matched crimes (joined):\", len(crime_joined))\n",
        "\n",
        "# Keep only what we need going forward: assigned zip + date\n",
        "crime_with_zip = crime_joined[[\"zip\", \"cmplnt_fr_dt\"]].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4790c642-6817-48f8-a25a-cd059a53e417",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Crime_counts rows: 4489\n",
            "     zip    month  crime_count\n",
            "0  10001  2023-02            1\n",
            "1  10001  2023-03            1\n",
            "2  10001  2023-10            3\n",
            "3  10001  2023-11            2\n",
            "4  10001  2024-01            3\n"
          ]
        }
      ],
      "source": [
        "# STEP 2) Count crimes per (zip, month)\n",
        "\n",
        "# Create month key as 'YYYY-MM' (same format as your df)\n",
        "crime_with_zip[\"month\"] = crime_with_zip[\"cmplnt_fr_dt\"].dt.to_period(\"M\").astype(str)\n",
        "\n",
        "crime_counts = (\n",
        "    crime_with_zip.groupby([\"zip\", \"month\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"crime_count\")\n",
        ")\n",
        "\n",
        "print(\"Crime_counts rows:\", len(crime_counts))\n",
        "print(crime_counts.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "450b35a3-65ac-485a-ae4a-d3272b2967bf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Non-NaN crime_count: 947052\n",
            "Total rows: 947052\n",
            "     zip    month           zhvi  population  median_income  poverty_base  \\\n",
            "0  01001  2023-01  284265.293218     16136.0        71924.0       15624.0   \n",
            "1  01001  2023-02  285125.304634     16136.0        71924.0       15624.0   \n",
            "2  01001  2023-03  286436.003321     16136.0        71924.0       15624.0   \n",
            "3  01001  2023-04  288442.991612     16136.0        71924.0       15624.0   \n",
            "4  01001  2023-05  290659.546155     16136.0        71924.0       15624.0   \n",
            "5  01001  2023-06  292723.607850     16136.0        71924.0       15624.0   \n",
            "6  01001  2023-07  294840.366054     16136.0        71924.0       15624.0   \n",
            "7  01001  2023-08  297214.654496     16136.0        71924.0       15624.0   \n",
            "8  01001  2023-09  299622.269960     16136.0        71924.0       15624.0   \n",
            "9  01001  2023-10  301303.118047     16136.0        71924.0       15624.0   \n",
            "\n",
            "   poverty_count  labor_force  unemployed  edu_bachelors  edu_masters  \\\n",
            "0         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "1         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "2         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "3         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "4         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "5         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "6         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "7         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "8         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "9         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "\n",
            "   edu_professional  edu_doctorate  poverty_rate  unemployment_rate  \\\n",
            "0             223.0          226.0      0.072325           0.051815   \n",
            "1             223.0          226.0      0.072325           0.051815   \n",
            "2             223.0          226.0      0.072325           0.051815   \n",
            "3             223.0          226.0      0.072325           0.051815   \n",
            "4             223.0          226.0      0.072325           0.051815   \n",
            "5             223.0          226.0      0.072325           0.051815   \n",
            "6             223.0          226.0      0.072325           0.051815   \n",
            "7             223.0          226.0      0.072325           0.051815   \n",
            "8             223.0          226.0      0.072325           0.051815   \n",
            "9             223.0          226.0      0.072325           0.051815   \n",
            "\n",
            "   higher_ed_count  crime_count  \n",
            "0           4365.0          0.0  \n",
            "1           4365.0          0.0  \n",
            "2           4365.0          0.0  \n",
            "3           4365.0          0.0  \n",
            "4           4365.0          0.0  \n",
            "5           4365.0          0.0  \n",
            "6           4365.0          0.0  \n",
            "7           4365.0          0.0  \n",
            "8           4365.0          0.0  \n",
            "9           4365.0          0.0  \n"
          ]
        }
      ],
      "source": [
        "# STEP 3) Merge crime_count into zillow_acs on (zip, month)\n",
        "df3 = df.merge(crime_counts, on=[\"zip\", \"month\"], how=\"left\")\n",
        "\n",
        "# Replace NaN in crime_count with 0\n",
        "df3[\"crime_count\"] = df3[\"crime_count\"].fillna(0)\n",
        "\n",
        "print(\"Non-NaN crime_count:\", df3[\"crime_count\"].notna().sum())\n",
        "print(\"Total rows:\", len(df3))\n",
        "print(df3.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e1babf65-6426-44ff-8293-be07826a7f98",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nStep4:\\n1. Convert the date column to datetime format. If the FRED data were daily or weekly, values were aggregated to the monthly level (e.g., monthly average).\\n2. Merge the monthly macroeconomic variables into df3 (ZIP-month dataset) using a left join on month.\\n\\n'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Step4:\n",
        "1. Convert the date column to datetime format. If the FRED data were daily or weekly, values were aggregated to the monthly level (e.g., monthly average).\n",
        "2. Merge the monthly macroeconomic variables into df3 (ZIP-month dataset) using a left join on month.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3d33a85b-ddb4-4297-8f62-a1afad0ce208",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FRED columns: Index(['date', 'series_id', 'value'], dtype='str')\n",
            "Shape: (947052, 18)\n",
            "     zip    month           zhvi  population  median_income  poverty_base  \\\n",
            "0  01001  2023-01  284265.293218     16136.0        71924.0       15624.0   \n",
            "1  01001  2023-02  285125.304634     16136.0        71924.0       15624.0   \n",
            "2  01001  2023-03  286436.003321     16136.0        71924.0       15624.0   \n",
            "3  01001  2023-04  288442.991612     16136.0        71924.0       15624.0   \n",
            "4  01001  2023-05  290659.546155     16136.0        71924.0       15624.0   \n",
            "\n",
            "   poverty_count  labor_force  unemployed  edu_bachelors  edu_masters  \\\n",
            "0         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "1         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "2         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "3         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "4         1130.0       8511.0       441.0         2660.0       1256.0   \n",
            "\n",
            "   edu_professional  edu_doctorate  poverty_rate  unemployment_rate  \\\n",
            "0             223.0          226.0      0.072325           0.051815   \n",
            "1             223.0          226.0      0.072325           0.051815   \n",
            "2             223.0          226.0      0.072325           0.051815   \n",
            "3             223.0          226.0      0.072325           0.051815   \n",
            "4             223.0          226.0      0.072325           0.051815   \n",
            "\n",
            "   higher_ed_count  crime_count     value  \n",
            "0           4365.0          0.0  5.230000  \n",
            "1           4365.0          0.0  5.920000  \n",
            "2           4365.0          0.0  6.228333  \n",
            "3           4365.0          0.0  6.040000  \n",
            "4           4365.0          0.0  6.152000  \n"
          ]
        }
      ],
      "source": [
        "df = df3.copy()\n",
        "\n",
        "# Ensure month format is string 'YYYY-MM'\n",
        "df[\"month\"] = df[\"month\"].astype(str)\n",
        "\n",
        "# 1) Read FRED data (newest from data/raw/fred/)\n",
        "if \"fred\" not in results or results[\"fred\"][1] is None:\n",
        "    raise FileNotFoundError(\"No FRED file found in data/raw/fred/. Run the fred acquirer first.\")\n",
        "_, fred = results[\"fred\"]\n",
        "fred = fred.copy()\n",
        "\n",
        "# Check column names\n",
        "print(\"FRED columns:\", fred.columns)\n",
        "\n",
        "fred[\"date\"] = pd.to_datetime(fred[\"date\"], errors=\"coerce\")\n",
        "\n",
        "# 2) Convert to Year-Month\n",
        "fred[\"month\"] = fred[\"date\"].dt.to_period(\"M\").astype(str)\n",
        "\n",
        "# 3) Aggregate to monthly level (if needed)\n",
        "fred_month = (\n",
        "    fred.groupby(\"month\")\n",
        "    .mean(numeric_only=True)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# 4) Merge with main dataset\n",
        "df4 = df.merge(fred_month, on=\"month\", how=\"left\")\n",
        "\n",
        "print(\"Shape:\", df4.shape)\n",
        "print(df4.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "cc545fee-450f-4769-9732-0cf3b6a5b937",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nStep6:\\n1. Assess the missing value. All variables had a missing ratio below 1%, with the highest being approximately 0.5% for zhvi.\\n2. Remove the missing values. All rows containing missing values were dropped from the dataset.\\n'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Step6:\n",
        "1. Assess the missing value. All variables had a missing ratio below 1%, with the highest being approximately 0.5% for zhvi.\n",
        "2. Remove the missing values. All rows containing missing values were dropped from the dataset.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f6fe2b0c-351b-49a4-9340-e1fd4d012cdc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   missing_count  missing_ratio\n",
            "zhvi                        4930       0.005206\n",
            "unemployment_rate           1224       0.001292\n",
            "poverty_rate                 504       0.000532\n",
            "unemployed                   324       0.000342\n",
            "edu_bachelors                324       0.000342\n",
            "population                   324       0.000342\n",
            "poverty_count                324       0.000342\n",
            "labor_force                  324       0.000342\n",
            "median_income                324       0.000342\n",
            "poverty_base                 324       0.000342\n",
            "edu_doctorate                324       0.000342\n",
            "higher_ed_count              324       0.000342\n",
            "edu_professional             324       0.000342\n",
            "edu_masters                  324       0.000342\n",
            "month                          0       0.000000\n",
            "zip                            0       0.000000\n",
            "crime_count                    0       0.000000\n",
            "value                          0       0.000000\n"
          ]
        }
      ],
      "source": [
        "# Missing data percent of each column\n",
        "df = df4.copy()\n",
        "missing_count = df.isna().sum()\n",
        "missing_ratio = df.isna().mean()\n",
        "missing_summary = pd.DataFrame({\n",
        "    \"missing_count\": missing_count,\n",
        "    \"missing_ratio\": missing_ratio\n",
        "})\n",
        "\n",
        "missing_summary = missing_summary.sort_values(by=\"missing_ratio\", ascending=False)\n",
        "\n",
        "print(missing_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "fe13c7e9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved preprocessed dataset:\n",
            "  Parquet: c:\\jason\\Columbia_stuff\\2025-2026\\DS\\project1\\data\\processed\\model_data.parquet\n",
            "  CSV:     c:\\jason\\Columbia_stuff\\2025-2026\\DS\\project1\\data\\processed\\model_data.csv\n",
            "  Shape:   (940922, 18)\n"
          ]
        }
      ],
      "source": [
        "# Save final preprocessed panel to data/processed/ (uses ROOT from cell 1)\n",
        "out_dir = ROOT / \"data\" / \"processed\"\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_parquet = out_dir / \"model_data.parquet\"\n",
        "out_csv = out_dir / \"model_data.csv\"\n",
        "\n",
        "df_clean.to_parquet(out_parquet, index=False)\n",
        "df_clean.to_csv(out_csv, index=False)\n",
        "\n",
        "print(f\"Saved preprocessed dataset:\")\n",
        "print(f\"  Parquet: {out_parquet}\")\n",
        "print(f\"  CSV:     {out_csv}\")\n",
        "print(f\"  Shape:   {df_clean.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b5e966b0-8cfb-4f1d-90de-1d2c14e6cb72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before drop: 947052\n",
            "After drop: 940922\n",
            "Dropped rows: 6130\n",
            "Remaining missing values:\n",
            "zip                  0\n",
            "month                0\n",
            "zhvi                 0\n",
            "population           0\n",
            "median_income        0\n",
            "poverty_base         0\n",
            "poverty_count        0\n",
            "labor_force          0\n",
            "unemployed           0\n",
            "edu_bachelors        0\n",
            "edu_masters          0\n",
            "edu_professional     0\n",
            "edu_doctorate        0\n",
            "poverty_rate         0\n",
            "unemployment_rate    0\n",
            "higher_ed_count      0\n",
            "crime_count          0\n",
            "value                0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_clean = df.dropna().copy()\n",
        "\n",
        "print(\"Before drop:\", len(df))\n",
        "print(\"After drop:\", len(df_clean))\n",
        "print(\"Dropped rows:\", len(df) - len(df_clean))\n",
        "\n",
        "print(\"Remaining missing values:\")\n",
        "print(df_clean.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4e70333b-fde8-4499-a51e-aef138e0751e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nStep7:\\n1.Descriptive Statistics Review:\\nSummary statistics and percentile distributions (1%, 5%, 95%, 99%) were examined for all numerical variables to identify extreme values.\\n2.Hard-Rule Validation:\\nLogical constraints were applied to detect impossible values (e.g., negative income, negative population, rates outside the [0,1] range).\\n3.IQR-Based Detection:\\nThe Interquartile Range (IQR) method was used to identify extreme observations outside [Q1−1.5×IQR,Q3+1.5×IQR]\\n4.Z-Score Detection:\\nStandardized Z-scores were calculated, and observations with ∣z∣>3 were flagged as potential outliers.\\n'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Step7:\n",
        "1.Descriptive Statistics Review:\n",
        "Summary statistics and percentile distributions (1%, 5%, 95%, 99%) were examined for all numerical variables to identify extreme values.\n",
        "2.Hard-Rule Validation:\n",
        "Logical constraints were applied to detect impossible values (e.g., negative income, negative population, rates outside the [0,1] range).\n",
        "3.IQR-Based Detection:\n",
        "The Interquartile Range (IQR) method was used to identify extreme observations outside [Q1−1.5×IQR,Q3+1.5×IQR]\n",
        "4.Z-Score Detection:\n",
        "Standardized Z-scores were calculated, and observations with ∣z∣>3 were flagged as potential outliers.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a7f979f3-d329-4ba5-bbc7-63639cbe844d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numeric columns for outlier check: ['zhvi', 'population', 'median_income', 'poverty_base', 'poverty_count', 'labor_force', 'unemployed', 'edu_bachelors', 'edu_masters', 'edu_professional', 'edu_doctorate', 'poverty_rate', 'unemployment_rate', 'higher_ed_count', 'crime_count', 'value']\n",
            "\n",
            "=== Descriptive stats (with percentiles) ===\n",
            "                      count          mean           std           min  \\\n",
            "zhvi               940922.0  3.432065e+05  3.027502e+05  2.589778e+04   \n",
            "population         940922.0  1.254596e+04  1.593857e+04  4.000000e+00   \n",
            "median_income      940922.0 -1.079581e+07  8.445204e+07 -6.666667e+08   \n",
            "poverty_base       940922.0  1.228761e+04  1.568268e+04  4.000000e+00   \n",
            "poverty_count      940922.0  1.522285e+03  2.430733e+03  0.000000e+00   \n",
            "labor_force        940922.0  6.384988e+03  8.375076e+03  2.000000e+00   \n",
            "unemployed         940922.0  3.305384e+02  5.148247e+02  0.000000e+00   \n",
            "edu_bachelors      940922.0  1.846570e+03  2.789274e+03  0.000000e+00   \n",
            "edu_masters        940922.0  8.533320e+02  1.410845e+03  0.000000e+00   \n",
            "edu_professional   940922.0  1.991214e+02  3.999376e+02  0.000000e+00   \n",
            "edu_doctorate      940922.0  1.409564e+02  2.995790e+02  0.000000e+00   \n",
            "poverty_rate       940922.0  1.236929e-01  8.454498e-02  0.000000e+00   \n",
            "unemployment_rate  940922.0  4.792273e-02  4.014798e-02  0.000000e+00   \n",
            "higher_ed_count    940922.0  3.039980e+03  4.733437e+03  0.000000e+00   \n",
            "crime_count        940922.0  6.033210e-01  1.556739e+01  0.000000e+00   \n",
            "value              940922.0  6.327998e+00  3.735817e-01  5.230000e+00   \n",
            "\n",
            "                             1%             5%            25%            50%  \\\n",
            "zhvi               7.069309e+04  106493.090002  178065.283767  263069.262172   \n",
            "population         1.850000e+02     419.000000    1540.000000    5054.000000   \n",
            "median_income     -6.666667e+08   38243.000000   56875.000000   71012.000000   \n",
            "poverty_base       1.840000e+02     415.000000    1520.000000    4911.000000   \n",
            "poverty_count      0.000000e+00      24.000000     150.000000     514.000000   \n",
            "labor_force        7.300000e+01     186.000000     710.000000    2379.000000   \n",
            "unemployed         0.000000e+00       0.000000      23.000000     103.000000   \n",
            "edu_bachelors      4.000000e+00      30.000000     142.000000     525.000000   \n",
            "edu_masters        0.000000e+00       6.000000      52.000000     214.000000   \n",
            "edu_professional   0.000000e+00       0.000000       5.000000      36.000000   \n",
            "edu_doctorate      0.000000e+00       0.000000       2.000000      24.000000   \n",
            "poverty_rate       0.000000e+00       0.025902       0.064083       0.105433   \n",
            "unemployment_rate  0.000000e+00       0.000000       0.024084       0.041657   \n",
            "higher_ed_count    1.200000e+01      48.000000     217.000000     813.000000   \n",
            "crime_count        0.000000e+00       0.000000       0.000000       0.000000   \n",
            "value              5.230000e+00       5.766000       6.152000       6.321667   \n",
            "\n",
            "                             75%            95%           99%           max  \n",
            "zhvi               403667.790056  823589.653855  1.497120e+06  7.801616e+06  \n",
            "population          18764.000000   45884.000000  6.827300e+04  1.372130e+05  \n",
            "median_income       90847.000000  139688.000000  1.965280e+05  2.500010e+05  \n",
            "poverty_base        18310.000000   45174.000000  6.736300e+04  1.368830e+05  \n",
            "poverty_count        1873.000000    6227.000000  1.144000e+04  3.327700e+04  \n",
            "labor_force          9439.000000   24218.000000  3.606200e+04  6.910300e+04  \n",
            "unemployed            434.000000    1367.000000  2.427000e+03  5.492000e+03  \n",
            "edu_bachelors        2467.000000    7770.000000  1.249800e+04  3.281300e+04  \n",
            "edu_masters          1066.000000    3740.000000  6.501000e+03  1.803900e+04  \n",
            "edu_professional      208.000000     962.000000  1.858000e+03  7.766000e+03  \n",
            "edu_doctorate         143.000000     666.000000  1.391000e+03  6.234000e+03  \n",
            "poverty_rate            0.163113       0.285200  4.055395e-01  1.000000e+00  \n",
            "unemployment_rate       0.062137       0.113761  1.858974e-01  1.000000e+00  \n",
            "higher_ed_count      3962.000000   12969.000000  2.122500e+04  5.592500e+04  \n",
            "crime_count             0.000000       0.000000  0.000000e+00  9.260000e+02  \n",
            "value                   6.522000       7.090000  7.162000e+00  7.162000e+00  \n",
            "\n",
            "=== Hard-rule outliers ===\n",
            "              column  hard_outlier_count  hard_outlier_ratio\n",
            "2      median_income               15346             0.01631\n",
            "0               zhvi                   0             0.00000\n",
            "1         population                   0             0.00000\n",
            "3        crime_count                   0             0.00000\n",
            "4       poverty_rate                   0             0.00000\n",
            "5  unemployment_rate                   0             0.00000\n",
            "\n",
            "=== IQR outliers (sorted) ===\n",
            "               column      iqr_lower      iqr_upper  iqr_outlier_count  \\\n",
            "10      edu_doctorate    -209.500000     354.500000             114693   \n",
            "9    edu_professional    -299.500000     512.500000             114474   \n",
            "8         edu_masters   -1469.000000    2587.000000              96324   \n",
            "13    higher_ed_count   -5400.500000    9579.500000              90780   \n",
            "4       poverty_count   -2434.500000    4457.500000              90273   \n",
            "7       edu_bachelors   -3345.500000    5954.500000              85020   \n",
            "6          unemployed    -593.500000    1050.500000              80838   \n",
            "15              value       5.597000       7.077000              77695   \n",
            "0                zhvi -160338.475666  742071.549489              60939   \n",
            "2       median_income    5917.000000  141805.000000              59676   \n",
            "5         labor_force  -12383.500000   22532.500000              58311   \n",
            "3        poverty_base  -23665.000000   43495.000000              53193   \n",
            "1          population  -24296.000000   44600.000000              51573   \n",
            "12  unemployment_rate      -0.032996       0.119217              41156   \n",
            "11       poverty_rate      -0.084461       0.311657              33209   \n",
            "14        crime_count            NaN            NaN                  0   \n",
            "\n",
            "    iqr_outlier_ratio  \n",
            "10           0.121894  \n",
            "9            0.121662  \n",
            "8            0.102372  \n",
            "13           0.096480  \n",
            "4            0.095941  \n",
            "7            0.090358  \n",
            "6            0.085914  \n",
            "15           0.082573  \n",
            "0            0.064765  \n",
            "2            0.063423  \n",
            "5            0.061972  \n",
            "3            0.056533  \n",
            "1            0.054811  \n",
            "12           0.043740  \n",
            "11           0.035294  \n",
            "14           0.000000  \n",
            "\n",
            "=== Z-score outliers (|z|>3) ===\n",
            "               column  z_outlier_count  z_outlier_ratio\n",
            "13    higher_ed_count            20664         0.021961\n",
            "7       edu_bachelors            20520         0.021808\n",
            "8         edu_masters            20484         0.021770\n",
            "4       poverty_count            20262         0.021534\n",
            "6          unemployed            20073         0.021333\n",
            "9    edu_professional            20016         0.021273\n",
            "10      edu_doctorate            18360         0.019513\n",
            "5         labor_force            17919         0.019044\n",
            "3        poverty_base            17199         0.018279\n",
            "1          population            17091         0.018164\n",
            "0                zhvi            16365         0.017393\n",
            "2       median_income            15346         0.016310\n",
            "12  unemployment_rate            13750         0.014613\n",
            "11       poverty_rate            13580         0.014433\n",
            "14        crime_count             1906         0.002026\n",
            "15              value                0         0.000000\n",
            "\n",
            "=== Top extremes (highest and lowest) for selected columns ===\n",
            "\n",
            "--- Column: zhvi (Top 10 high) ---\n",
            "          zip    month          zhvi\n",
            "887903  94027  2025-12  7.801616e+06\n",
            "887902  94027  2025-11  7.685470e+06\n",
            "887901  94027  2025-10  7.559730e+06\n",
            "887900  94027  2025-09  7.457884e+06\n",
            "887899  94027  2025-08  7.367609e+06\n",
            "887890  94027  2024-11  7.346104e+06\n",
            "887891  94027  2024-12  7.343196e+06\n",
            "887896  94027  2025-05  7.327763e+06\n",
            "887868  94027  2023-01  7.327194e+06\n",
            "887898  94027  2025-07  7.326864e+06\n",
            "--- Column: zhvi (Top 10 low) ---\n",
            "          zip    month          zhvi\n",
            "716867  71103  2025-12  25897.782803\n",
            "716866  71103  2025-11  26184.251458\n",
            "716865  71103  2025-10  26497.959214\n",
            "716864  71103  2025-09  26729.049150\n",
            "716863  71103  2025-08  26915.334913\n",
            "716862  71103  2025-07  27082.208250\n",
            "716861  71103  2025-06  27247.555570\n",
            "486432  48505  2023-01  27569.308543\n",
            "716860  71103  2025-05  27665.972702\n",
            "486433  48505  2023-02  27733.801722\n",
            "\n",
            "--- Column: crime_count (Top 10 high) ---\n",
            "         zip    month  crime_count\n",
            "84954  11212  2025-07        926.0\n",
            "84953  11212  2025-06        893.0\n",
            "84773  11207  2025-06        891.0\n",
            "84951  11212  2025-04        889.0\n",
            "84774  11207  2025-07        885.0\n",
            "84808  11208  2025-05        875.0\n",
            "84770  11207  2025-03        872.0\n",
            "84776  11207  2025-09        865.0\n",
            "84952  11212  2025-05        865.0\n",
            "84772  11207  2025-05        864.0\n",
            "--- Column: crime_count (Top 10 low) ---\n",
            "          zip    month  crime_count\n",
            "947042  99929  2025-03          0.0\n",
            "17      01001  2024-06          0.0\n",
            "18      01001  2024-07          0.0\n",
            "19      01001  2024-08          0.0\n",
            "20      01001  2024-09          0.0\n",
            "21      01001  2024-10          0.0\n",
            "22      01001  2024-11          0.0\n",
            "23      01001  2024-12          0.0\n",
            "24      01001  2025-01          0.0\n",
            "25      01001  2025-02          0.0\n",
            "\n",
            "--- Column: median_income (Top 10 high) ---\n",
            "          zip    month  median_income\n",
            "646646  63073  2024-03       250001.0\n",
            "646653  63073  2024-10       250001.0\n",
            "320758  33109  2025-11       250001.0\n",
            "320757  33109  2025-10       250001.0\n",
            "320756  33109  2025-09       250001.0\n",
            "320755  33109  2025-08       250001.0\n",
            "320754  33109  2025-07       250001.0\n",
            "320753  33109  2025-06       250001.0\n",
            "320750  33109  2025-03       250001.0\n",
            "320749  33109  2025-02       250001.0\n",
            "--- Column: median_income (Top 10 low) ---\n",
            "          zip    month  median_income\n",
            "242957  26662  2025-06   -666666666.0\n",
            "712962  70581  2024-07   -666666666.0\n",
            "712961  70581  2024-06   -666666666.0\n",
            "712960  70581  2024-05   -666666666.0\n",
            "712959  70581  2024-04   -666666666.0\n",
            "712958  70581  2024-03   -666666666.0\n",
            "712957  70581  2024-02   -666666666.0\n",
            "808832  80476  2024-09   -666666666.0\n",
            "808831  80476  2024-08   -666666666.0\n",
            "808830  80476  2024-07   -666666666.0\n",
            "\n",
            "--- Column: population (Top 10 high) ---\n",
            "          zip    month  population\n",
            "779801  77494  2023-06    137213.0\n",
            "779800  77494  2023-05    137213.0\n",
            "779819  77494  2024-12    137213.0\n",
            "779799  77494  2023-04    137213.0\n",
            "779827  77494  2025-08    137213.0\n",
            "779823  77494  2025-04    137213.0\n",
            "779818  77494  2024-11    137213.0\n",
            "779817  77494  2024-10    137213.0\n",
            "779816  77494  2024-09    137213.0\n",
            "779815  77494  2024-08    137213.0\n",
            "--- Column: population (Top 10 low) ---\n",
            "          zip    month  population\n",
            "885000  93623  2024-01         4.0\n",
            "885001  93623  2024-02         4.0\n",
            "885002  93623  2024-03         4.0\n",
            "885003  93623  2024-04         4.0\n",
            "885012  93623  2025-01         4.0\n",
            "885013  93623  2025-02         4.0\n",
            "885014  93623  2025-03         4.0\n",
            "885015  93623  2025-04         4.0\n",
            "885023  93623  2025-12         4.0\n",
            "885008  93623  2024-09         4.0\n",
            "\n",
            "Rows flagged as outliers (IQR on selected cols): 60939\n"
          ]
        }
      ],
      "source": [
        "# outlier detectives\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "df = df_clean.copy()\n",
        "\n",
        "# ====== 1) Pick numeric columns (exclude keys) ======\n",
        "# We only run outlier checks on numeric columns.\n",
        "key_cols = [\"zip\", \"month\"]\n",
        "num_cols = []\n",
        "for c in df.columns:\n",
        "    if c in key_cols:\n",
        "        continue\n",
        "    if pd.api.types.is_numeric_dtype(df[c]):\n",
        "        num_cols.append(c)\n",
        "\n",
        "print(\"Numeric columns for outlier check:\", num_cols)\n",
        "\n",
        "# ====== 2) Basic descriptive stats (quick scan) ======\n",
        "desc = df[num_cols].describe(percentiles=[0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99]).T\n",
        "print(\"\\n=== Descriptive stats (with percentiles) ===\")\n",
        "print(desc)\n",
        "\n",
        "# ====== 3) Hard-rule checks (impossible / suspicious values) ======\n",
        "hard_rules = {\n",
        "    \"zhvi\": lambda s: (s <= 0),\n",
        "    \"population\": lambda s: (s < 0),\n",
        "    \"median_income\": lambda s: (s < 0),\n",
        "    \"crime_count\": lambda s: (s < 0),\n",
        "    \"poverty_rate\": lambda s: (s < 0) | (s > 1),\n",
        "    \"unemployment_rate\": lambda s: (s < 0) | (s > 1),\n",
        "}\n",
        "\n",
        "hard_summary = []\n",
        "for col, rule_fn in hard_rules.items():\n",
        "    if col in df.columns:\n",
        "        mask = rule_fn(df[col])\n",
        "        hard_summary.append({\n",
        "            \"column\": col,\n",
        "            \"hard_outlier_count\": int(mask.sum()),\n",
        "            \"hard_outlier_ratio\": float(mask.mean())\n",
        "        })\n",
        "\n",
        "hard_summary = pd.DataFrame(hard_summary).sort_values(\"hard_outlier_count\", ascending=False)\n",
        "print(\"\\n=== Hard-rule outliers ===\")\n",
        "print(hard_summary)\n",
        "\n",
        "# ====== 4) IQR outlier detection (robust) ======\n",
        "iqr_summary = []\n",
        "iqr_masks = {}  # store masks to inspect rows later\n",
        "\n",
        "for col in num_cols:\n",
        "    s = df[col].dropna()\n",
        "    if len(s) == 0:\n",
        "        continue\n",
        "\n",
        "    q1 = s.quantile(0.25)\n",
        "    q3 = s.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "\n",
        "    # If IQR is 0 (constant-ish column), skip to avoid division issues\n",
        "    if pd.isna(iqr) or iqr == 0:\n",
        "        iqr_summary.append({\n",
        "            \"column\": col,\n",
        "            \"iqr_lower\": np.nan,\n",
        "            \"iqr_upper\": np.nan,\n",
        "            \"iqr_outlier_count\": 0,\n",
        "            \"iqr_outlier_ratio\": 0.0\n",
        "        })\n",
        "        iqr_masks[col] = pd.Series(False, index=df.index)\n",
        "        continue\n",
        "\n",
        "    lower = q1 - 1.5 * iqr\n",
        "    upper = q3 + 1.5 * iqr\n",
        "\n",
        "    mask = (df[col] < lower) | (df[col] > upper)\n",
        "    iqr_masks[col] = mask\n",
        "\n",
        "    iqr_summary.append({\n",
        "        \"column\": col,\n",
        "        \"iqr_lower\": float(lower),\n",
        "        \"iqr_upper\": float(upper),\n",
        "        \"iqr_outlier_count\": int(mask.sum()),\n",
        "        \"iqr_outlier_ratio\": float(mask.mean())\n",
        "    })\n",
        "\n",
        "iqr_summary = pd.DataFrame(iqr_summary).sort_values(\"iqr_outlier_count\", ascending=False)\n",
        "print(\"\\n=== IQR outliers (sorted) ===\")\n",
        "print(iqr_summary)\n",
        "\n",
        "# ====== 5) Z-score outlier detection (|z| > 3) ======\n",
        "z_summary = []\n",
        "z_masks = {}\n",
        "\n",
        "for col in num_cols:\n",
        "    s = df[col]\n",
        "    mean = s.mean()\n",
        "    std = s.std()\n",
        "\n",
        "    # If std is 0 or NaN, no z-score outliers\n",
        "    if pd.isna(std) or std == 0:\n",
        "        z_masks[col] = pd.Series(False, index=df.index)\n",
        "        z_summary.append({\n",
        "            \"column\": col,\n",
        "            \"z_outlier_count\": 0,\n",
        "            \"z_outlier_ratio\": 0.0\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    z = (s - mean) / std\n",
        "    mask = z.abs() > 3\n",
        "    z_masks[col] = mask\n",
        "\n",
        "    z_summary.append({\n",
        "        \"column\": col,\n",
        "        \"z_outlier_count\": int(mask.sum()),\n",
        "        \"z_outlier_ratio\": float(mask.mean())\n",
        "    })\n",
        "\n",
        "z_summary = pd.DataFrame(z_summary).sort_values(\"z_outlier_count\", ascending=False)\n",
        "print(\"\\n=== Z-score outliers (|z|>3) ===\")\n",
        "print(z_summary)\n",
        "\n",
        "# ====== 6) (Optional) Inspect top extreme rows for key columns ======\n",
        "# This helps to quickly see which zip-month combos are extreme.\n",
        "cols_to_inspect = [\"zhvi\", \"crime_count\", \"median_income\", \"population\"]\n",
        "cols_to_inspect = [c for c in cols_to_inspect if c in df.columns]\n",
        "\n",
        "print(\"\\n=== Top extremes (highest and lowest) for selected columns ===\")\n",
        "for col in cols_to_inspect:\n",
        "    print(f\"\\n--- Column: {col} (Top 10 high) ---\")\n",
        "    print(df.sort_values(col, ascending=False)[[\"zip\",\"month\",col]].head(10))\n",
        "    print(f\"--- Column: {col} (Top 10 low) ---\")\n",
        "    print(df.sort_values(col, ascending=True)[[\"zip\",\"month\",col]].head(10))\n",
        "\n",
        "# ====== 7) (Optional) Create a combined outlier flag (for review only) ======\n",
        "flag_cols = [c for c in [\"zhvi\", \"crime_count\"] if c in df.columns]\n",
        "df_outlier_flag = df.copy()\n",
        "\n",
        "df_outlier_flag[\"outlier_flag\"] = False\n",
        "for c in flag_cols:\n",
        "    df_outlier_flag[\"outlier_flag\"] = df_outlier_flag[\"outlier_flag\"] | iqr_masks[c]\n",
        "\n",
        "print(\"\\nRows flagged as outliers (IQR on selected cols):\", df_outlier_flag[\"outlier_flag\"].sum())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
